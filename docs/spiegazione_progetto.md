# Presentazione Progetto Smart ATS - Sistema Cloud-Native su AWS

**Studente**: Salvatore Leanza  
**Corso**: Sistemi Cloud  
**Anno Accademico**: 2025/2026

---

## ğŸ“‹ Indice

1. [Introduzione al Progetto](#introduzione)
2. [Architettura Cloud-Native](#architettura)
3. [Tecnologie AWS Utilizzate](#tecnologie-aws)
4. [Implementazione Dettagliata](#implementazione)
5. [Sicurezza e Best Practices](#sicurezza)
6. [Testing e Deployment](#testing)
7. [Dimostrazione Pratica](#dimostrazione)

---

## 1. Introduzione al Progetto {#introduzione}

### Il Problema

Le aziende ricevono centinaia di CV per ogni posizione aperta. Il processo manuale di screening Ã¨:
- **Lento**: Un recruiter impiega 5-10 minuti per CV
- **Inconsistente**: Valutazioni soggettive
- **Non scalabile**: Impossibile gestire grandi volumi

### La Soluzione: Smart ATS

Un **Applicant Tracking System intelligente** che:
- **Automatizza** il parsing dei CV (PDF, DOCX)
- **Analizza** competenze, esperienza ed educazione
- **Classifica** i candidati con uno score oggettivo
- **Scala automaticamente** grazie all'architettura serverless

### Obiettivi del Progetto

1. âœ… Implementare un'architettura **completamente serverless** su AWS
2. âœ… Processare CV in modo **asincrono** e scalabile
3. âœ… Garantire **sicurezza** tramite autenticazione Cognito
4. âœ… Utilizzare **Infrastructure as Code** (AWS SAM)
5. âœ… Dimostrare **best practices** cloud-native

---

## 2. Architettura Cloud-Native {#architettura}

### Diagramma Architettura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚ Recruiter accede via web
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AWS Cognito User Pool                     â”‚
â”‚  - Autenticazione JWT                               â”‚
â”‚  - User: admin@smartats.com                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Flask Application (Docker + Gunicorn)        â”‚
â”‚  - Dashboard per upload CV                          â”‚
â”‚  - Visualizzazione ranking candidati                â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                          â”‚
       â”‚ Upload CV                â”‚ Query candidati
       â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AWS S3      â”‚          â”‚   DynamoDB       â”‚
â”‚  Bucket      â”‚          â”‚   Table          â”‚
â”‚              â”‚          â”‚                  â”‚
â”‚ smart-ats-   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Candidati        â”‚
â”‚ cvs-dev-*    â”‚  Legge   â”‚ processati       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                         â”‚
       â”‚ S3 Event                â”‚ Scrive
       â”‚ Notification            â”‚ risultati
       â–¼                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  AWS SQS     â”‚                 â”‚
â”‚  Queue       â”‚                 â”‚
â”‚              â”‚                 â”‚
â”‚ cv-queue-dev â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
       â”‚                         â”‚
       â”‚ Trigger                 â”‚
       â–¼                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   AWS Lambda Function        â”‚ â”‚
â”‚   smart-ats-cv-processor     â”‚â”€â”˜
â”‚                              â”‚
â”‚  1. Download CV da S3        â”‚
â”‚  2. Parse PDF/DOCX           â”‚
â”‚  3. Extract info (skills...)â”‚
â”‚  4. Calculate ranking score  â”‚
â”‚  5. Write to DynamoDB        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Principi Architetturali

#### **1. Event-Driven Architecture**
- Ogni upload CV genera un evento S3
- Eventi processati in modo **asincrono** tramite SQS
- **Disaccoppiamento** tra componenti

#### **2. Serverless-First**
- **Zero gestione server**: AWS gestisce infrastruttura
- **Auto-scaling**: Scala automaticamente con il carico
- **Pay-per-use**: Costi solo quando in uso

#### **3. Microservices Pattern**
- Ogni componente ha una **singola responsabilitÃ **
- Componenti **indipendentemente scalabili**
- Facile manutenzione e testing

---

## 3. Tecnologie AWS Utilizzate {#tecnologie-aws}

### 3.1 AWS S3 (Simple Storage Service)

**Ruolo**: Storage per i file CV caricati

**Configurazione**:
```yaml
CVStorageBucket:
  Type: AWS::S3::Bucket
  Properties:
    BucketName: !Sub smart-ats-cvs-${Environment}-${AWS::AccountId}
    VersioningConfiguration:
      Status: Enabled  # Mantiene versioni dei file
    PublicAccessBlockConfiguration:
      BlockPublicAcls: true
      BlockPublicPolicy: true
      IgnorePublicAcls: true
      RestrictPublicBuckets: true  # Sicurezza: bucket privato
```

**FunzionalitÃ  Implementate**:
1. **Event Notifications**: Invia eventi a SQS quando un file viene caricato
2. **Versioning**: Mantiene storico modifiche
3. **Lifecycle Rules**: Elimina versioni vecchie dopo 90 giorni
4. **Encryption**: Dati cifrati at-rest (AES-256)

**PerchÃ© S3?**
- âœ… ScalabilitÃ  illimitata
- âœ… 99.999999999% durability (11 nines)
- âœ… Storage economico ($0.023/GB al mese)
- âœ… Integrazione nativa con altri servizi AWS

---

### 3.2 AWS SQS (Simple Queue Service)

**Ruolo**: Coda messaggi per processing asincrono

**Configurazione**:
```yaml
CVProcessingQueue:
  Type: AWS::SQS::Queue
  Properties:
    QueueName: !Sub smart-ats-cv-queue-${Environment}
    VisibilityTimeout: 900  # 15 minuti
    MessageRetentionPeriod: 1209600  # 14 giorni
    ReceiveMessageWaitTimeSeconds: 20  # Long polling
    RedrivePolicy:
      deadLetterTargetArn: !GetAtt CVProcessingDLQ.Arn
      maxReceiveCount: 3  # Dopo 3 fallimenti â†’ DLQ
```

**Pattern Implementato: Dead Letter Queue (DLQ)**
```
Messaggio â†’ Queue Principale â†’ Lambda
              â†“ (se fallisce 3 volte)
            DLQ (per analisi errori)
```

**Vantaggi SQS**:
- âœ… **Buffering**: Assorbe picchi di traffico
- âœ… **Retry automatico**: Riprova messaggi falliti
- âœ… **At-least-once delivery**: Garantisce elaborazione
- âœ… **Long polling**: Riduce costi (meno richieste API)

**Flusso Messaggi**:
```python
# S3 invia messaggio quando CV caricato
{
  "Records": [{
    "s3": {
      "bucket": {"name": "smart-ats-cvs-dev-*"},
      "object": {"key": "cvs/john_doe_20260116.pdf"}
    }
  }]
}
```

---

### 3.3 AWS Lambda

**Ruolo**: Serverless compute per processare CV

**Configurazione**:
```yaml
CVProcessorFunction:
  Type: AWS::Serverless::Function
  Properties:
    FunctionName: !Sub smart-ats-cv-processor-${Environment}
    Runtime: python3.13
    Handler: handler.lambda_handler
    MemorySize: 512  # MB RAM allocata
    Timeout: 300     # 5 minuti max
    Environment:
      Variables:
        DYNAMODB_TABLE: !Ref CandidatesTable
        S3_BUCKET: !Ref CVStorageBucket
    Events:
      SQSEvent:
        Type: SQS
        Properties:
          Queue: !GetAtt CVProcessingQueue.Arn
          BatchSize: 10  # Processa fino a 10 CV alla volta
```

**Codice Lambda Handler**:
```python
from decimal import Decimal
import boto3
import json

def lambda_handler(event, context):
    """
    Triggered by SQS messages from S3 events.
    Processes CV files and stores rankings in DynamoDB.
    """
    s3_client = boto3.client('s3')
    dynamodb = boto3.resource('dynamodb')
    table = dynamodb.Table(os.environ['DYNAMODB_TABLE'])
    
    for record in event['Records']:
        # Parse SQS message with S3 event
        message = json.loads(record['body'])
        s3_event = message['Records'][0]
        
        bucket = s3_event['s3']['bucket']['name']
        key = s3_event['s3']['object']['key']
        
        # 1. Download CV from S3
        cv_content = s3_client.get_object(Bucket=bucket, Key=key)['Body'].read()
        
        # 2. Parse CV (extract name, skills, experience)
        parser = CVParser()
        cv_data = parser.parse(cv_content, key)
        
        # 3. Calculate ranking score
        ranker = RankingEngine()
        score, skills_matched = ranker.calculate_score(cv_data, 'Software Engineer')
        
        # 4. Store in DynamoDB (type Decimal per compatibilitÃ  DynamoDB)
        table.put_item(Item={
            'candidate_id': f"{cv_data['name']}_{datetime.now().timestamp()}",
            'candidate_name': cv_data['name'],
            'ranking_score': Decimal(str(score)),
            'skills': cv_data['skills'],
            'status': 'processed'
        })
    
    return {'statusCode': 200}
```

**Vantaggi Lambda**:
- âœ… **Zero gestione server**: AWS gestisce OS, patching, scaling
- âœ… **Scaling automatico**: Da 0 a 1000+ istanze in secondi
- âœ… **Costo**: Solo per tempo di esecuzione effettivo
- âœ… **Integrazione nativa**: Con SQS, S3, DynamoDB

**Pricing Example**:
- 1 milione richieste/mese: **GRATIS** (Free Tier)
- 512MB RAM Ã— 1s esecuzione Ã— 1000 invocazioni = $0.01

---

### 3.4 AWS DynamoDB

**Ruolo**: Database NoSQL per memorizzare candidati e ranking

**Configurazione**:
```yaml
CandidatesTable:
  Type: AWS::DynamoDB::Table
  Properties:
    TableName: !Sub smart-ats-candidates-${Environment}
    BillingMode: PAY_PER_REQUEST  # On-demand, no capacity planning
    AttributeDefinitions:
      - AttributeName: candidate_id
        AttributeType: S  # String
      - AttributeName: job_position
        AttributeType: S
      - AttributeName: ranking_score
        AttributeType: N  # Number (Decimal)
    KeySchema:
      - AttributeName: candidate_id
        KeyType: HASH  # Partition key
    GlobalSecondaryIndexes:
      - IndexName: JobPositionRankingIndex
        KeySchema:
          - AttributeName: job_position
            KeyType: HASH
          - AttributeName: ranking_score
            KeyType: RANGE  # Sort key
        Projection:
          ProjectionType: ALL
```

**Schema Item**:
```json
{
  "candidate_id": "John Doe_1768587600.576779",
  "candidate_name": "John Doe",
  "email": "john.doe@email.com",
  "phone": "+39 333 1234567",
  "job_position": "Software Engineer",
  "ranking_score": 87.5,
  "skills": ["Python", "AWS", "Docker", "JavaScript"],
  "experience_years": 5,
  "education": "Master's Degree",
  "status": "processed",
  "upload_date": "2026-01-20 17:00:00"
}
```

**Query Ottimizzate con GSI**:
```python
# Query candidati per posizione, ordinati per score (DECRESCENTE)
response = table.query(
    IndexName='JobPositionRankingIndex',
    KeyConditionExpression='job_position = :pos',
    ExpressionAttributeValues={':pos': 'Software Engineer'},
    ScanIndexForward=False  # Ordine decrescente
)
```

**Vantaggi DynamoDB**:
- âœ… **Performance**: <10ms latenza anche con milioni di record
- âœ… **Auto-scaling**: Scala read/write capacity automaticamente
- âœ… **Global Tables**: Multi-region replication
- âœ… **No maintenance**: Fully managed

---

### 3.5 AWS Cognito

**Ruolo**: Autenticazione e gestione utenti

**Configurazione**:
```yaml
UserPool:
  Type: AWS::Cognito::UserPool
  Properties:
    UserPoolName: !Sub smart-ats-users-${Environment}
    AutoVerifiedAttributes:
      - email
    UsernameAttributes:
      - email  # Login con email invece di username
    Policies:
      PasswordPolicy:
        MinimumLength: 8
        RequireUppercase: true
        RequireLowercase: true
        RequireNumbers: true
    AdminCreateUserConfig:
      AllowAdminCreateUserOnly: true  # Solo admin crea utenti
```

**Flusso Autenticazione**:
```python
# 1. User login via Flask frontend
from warrant import Cognito

def login():
    username = request.form['username']
    password = request.form['password']
    
    # 2. Authenticate con Cognito
    cognito = Cognito(
        user_pool_id=COGNITO_USER_POOL_ID,
        client_id=COGNITO_CLIENT_ID,
        username=username
    )
    
    # 3. Authenticate and get JWT tokens
    cognito.authenticate(password=password)
    
    # 4. Store ID token in session
    session['id_token'] = cognito.id_token
    session['username'] = username
    
    return redirect('/dashboard')
```

**JWT Token Structure**:
```json
{
  "sub": "uuid-user-id",
  "email": "admin@smartats.com",
  "cognito:username": "admin@smartats.com",
  "exp": 1768591200,  # Expiration timestamp
  "iat": 1768587600   # Issued at
}
```

**Vantaggi Cognito**:
- âœ… **Sicurezza**: Password hashing, MFA, OAuth2
- âœ… **ScalabilitÃ **: Gestisce milioni di utenti
- âœ… **Compliance**: GDPR, HIPAA ready
- âœ… **Integrazione**: Con API Gateway, Lambda

---

### 3.6 AWS API Gateway

**Ruolo**: REST API endpoint (attualmente usato minimamente, espandibile)

**Configurazione**:
```yaml
SmartATSApi:
  Type: AWS::Serverless::Api
  Properties:
    Name: !Sub smart-ats-api-${Environment}
    StageName: !Ref Environment
    Auth:
      DefaultAuthorizer: CognitoAuthorizer
      Authorizers:
        CognitoAuthorizer:
          UserPoolArn: !GetAtt UserPool.Arn
    Cors:
      AllowMethods: "'GET,POST,PUT,DELETE,OPTIONS'"
      AllowHeaders: "'Content-Type,Authorization'"
      AllowOrigin: "'*'"
```

**Endpoint Implementato**:
```
GET /health â†’ Healthcheck API
GET /candidates?position=SoftwareEngineer â†’ Future: Query candidati via API
```

**Future Enhancements**:
- API REST completa per CRUD candidati
- Webhooks per notifiche
- GraphQL endpoint

---

### 3.7 AWS SAM (Serverless Application Model)

**Ruolo**: Infrastructure as Code

**Template SAM** (`template.yaml`):
```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: Smart ATS - Serverless Applicant Tracking System

Parameters:
  Environment:
    Type: String
    Default: dev
    AllowedValues: [dev, staging, prod]

Globals:
  Function:
    Timeout: 300
    MemorySize: 512
    Runtime: python3.13
    Environment:
      Variables:
        ENVIRONMENT: !Ref Environment

Resources:
  # S3, SQS, Lambda, DynamoDB, Cognito, API Gateway...
  # (come visto nelle sezioni precedenti)

Outputs:
  S3BucketName:
    Value: !Ref CVStorageBucket
  ApiEndpoint:
    Value: !Sub https://${SmartATSApi}.execute-api.${AWS::Region}.amazonaws.com/${Environment}
  UserPoolId:
    Value: !Ref UserPool
```

**Comandi Deployment**:
```bash
# Build (compila Lambda in container Docker)
sam build --use-container

# Deploy su AWS
sam deploy \
  --stack-name smart-ats-stack-dev \
  --region us-east-1 \
  --capabilities CAPABILITY_IAM \
  --parameter-overrides Environment=dev
```

**Vantaggi SAM**:
- âœ… **ReproducibilitÃ **: Stessa infrastruttura in dev/staging/prod
- âœ… **Versioning**: Template in Git
- âœ… **Rollback automatico**: Se deploy fallisce
- âœ… **Local testing**: `sam local invoke` per test locali

---

## 4. Implementazione Dettagliata {#implementazione}

### 4.1 CV Parser (Python)

**File**: `lambda/cv_processor/utils/cv_parser.py`

```python
import PyPDF2
from docx import Document
import re

class CVParser:
    def parse(self, cv_content, filename):
        """Parse PDF or DOCX CV file."""
        if filename.endswith('.pdf'):
            return self._parse_pdf(cv_content)
        elif filename.endswith(('.doc', '.docx')):
            return self._parse_docx(cv_content)
        else:
            return self._parse_text(cv_content)
    
    def _parse_pdf(self, content):
        """Extract text from PDF."""
        pdf = PyPDF2.PdfReader(BytesIO(content))
        text = ' '.join([page.extract_text() for page in pdf.pages])
        return self._extract_info(text)
    
    def _extract_info(self, text):
        """Extract structured information from text."""
        return {
            'name': self._extract_name(text),
            'email': self._extract_email(text),
            'phone': self._extract_phone(text),
            'skills': self._extract_skills(text),
            'experience_years': self._extract_experience(text),
            'education': self._extract_education(text)
        }
    
    def _extract_email(self, text):
        """Extract email using regex."""
        pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        match = re.search(pattern, text)
        return match.group(0) if match else 'N/A'
    
    def _extract_skills(self, text):
        """Extract skills by keyword matching."""
        skill_keywords = [
            'Python', 'Java', 'JavaScript', 'AWS', 'Docker',
            'Kubernetes', 'SQL', 'React', 'Node.js', 'Git',
            'Machine Learning', 'AI', 'Cloud', 'DevOps'
        ]
        
        found_skills = []
        text_lower = text.lower()
        for skill in skill_keywords:
            if skill.lower() in text_lower:
                found_skills.append(skill)
        
        return found_skills
    
    def _extract_experience(self, text):
        """Extract years of experience."""
        # Pattern: "2020-2024" â†’ 4 years
        year_pattern = r'(\d{4})\s*[-â€“]\s*(\d{4}|present|oggi)'
        matches = re.findall(year_pattern, text, re.IGNORECASE)
        
        total_years = 0
        for start, end in matches:
            end_year = 2026 if 'present' in end.lower() else int(end)
            total_years += end_year - int(start)
        
        return total_years
```

---

### 4.2 Ranking Engine (Python)

**File**: `lambda/cv_processor/utils/ranking_engine.py`

```python
class RankingEngine:
    def __init__(self):
        # Job-specific requirements
        self.job_requirements = {
            'Software Engineer': {
                'skills': ['python', 'java', 'javascript', 'git', 'sql'],
                'min_experience': 2,
                'education_weight': 0.2
            },
            'Cloud Engineer': {
                'skills': ['aws', 'docker', 'kubernetes', 'terraform'],
                'min_experience': 3,
                'education_weight': 0.15
            }
        }
    
    def calculate_score(self, cv_data, job_position='General'):
        """
        Calculate ranking score using weighted algorithm.
        
        Formula:
        Total Score = (Skills Ã— 50%) + (Experience Ã— 30%) + (Education Ã— 20%)
        """
        requirements = self.job_requirements.get(
            job_position, 
            self.job_requirements['General']
        )
        
        # 1. Skills matching (50% weight)
        skills_score = self._calculate_skills_score(
            cv_data['skills'], 
            requirements['skills']
        )
        
        # 2. Experience score (30% weight)
        experience_score = self._calculate_experience_score(
            cv_data['experience_years'],
            requirements['min_experience']
        )
        
        # 3. Education score (20% weight)
        education_score = self._calculate_education_score(
            cv_data['education']
        )
        
        # Weighted total
        total_score = (
            skills_score * 0.5 +
            experience_score * 0.3 +
            education_score * 0.2
        ) * 100
        
        return round(total_score, 2)
    
    def _calculate_skills_score(self, candidate_skills, required_skills):
        """Score basato su quante skills required sono presenti."""
        if not required_skills:
            return 1.0
        
        matched = sum(
            1 for skill in required_skills 
            if skill.lower() in [s.lower() for s in candidate_skills]
        )
        
        return matched / len(required_skills)
    
    def _calculate_experience_score(self, years, min_required):
        """Score basato su anni esperienza."""
        if years >= min_required + 3:
            return 1.0  # Esperienza eccellente
        elif years >= min_required:
            return 0.7 + (years - min_required) * 0.1
        else:
            return max(0.2, years * 0.1)  # Minimo 20%
```

**Esempio Calcolo**:
```
Candidato: 
  - Skills: ['Python', 'Git', 'AWS']
  - Experience: 4 anni
  - Education: Master's Degree

Job: Software Engineer
  - Required skills: ['python', 'java', 'javascript', 'git', 'sql']
  - Min experience: 2 anni

Calcolo:
1. Skills: 2/5 matched = 0.4 â†’ 0.4 Ã— 50% = 20 punti
2. Experience: 4 anni â‰¥ 2+1 â†’ 0.8 Ã— 30% = 24 punti
3. Education: Master = 0.9 â†’ 0.9 Ã— 20% = 18 punti

TOTAL: 20 + 24 + 18 = 62/100 âœ…
```

---

### 4.3 Frontend Flask Application

**File**: `frontend/app.py`

```python
from flask import Flask, render_template, request, redirect, session
import boto3
from warrant import Cognito

app = Flask(__name__)
app.secret_key = os.environ.get('SECRET_KEY')

# AWS Clients
s3_client = boto3.client('s3', region_name=os.environ['AWS_REGION'])
dynamodb = boto3.resource('dynamodb', region_name=os.environ['AWS_REGION'])

@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        username = request.form['username']
        password = request.form['password']
        
        try:
            # Authenticate with Cognito
            cognito = Cognito(
                user_pool_id=os.environ['COGNITO_USER_POOL_ID'],
                client_id=os.environ['COGNITO_CLIENT_ID'],
                username=username
            )
            cognito.authenticate(password=password)
            
            # Store session
            session['id_token'] = cognito.id_token
            session['username'] = username
            
            return redirect('/dashboard')
        except Exception as e:
            flash(f'Login error: {str(e)}', 'error')
    
    return render_template('login.html')

@app.route('/dashboard')
def dashboard():
    if 'id_token' not in session:
        return redirect('/login')
    
    # Query DynamoDB for candidates
    table = dynamodb.Table(os.environ['DYNAMODB_TABLE'])
    response = table.scan()
    
    # Sort by ranking_score descending
    candidates = sorted(
        response['Items'], 
        key=lambda x: float(x.get('ranking_score', 0)), 
        reverse=True
    )
    
    return render_template('dashboard.html', 
                         candidates=candidates,
                         username=session['username'])

@app.route('/upload', methods=['POST'])
def upload_cv():
    """Upload CV to S3, trigger async processing."""
    file = request.files['cv_file']
    job_position = request.form['job_position']
    
    # Generate unique filename
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"cvs/{timestamp}_{secure_filename(file.filename)}"
    
    # Upload to S3 with metadata
    s3_client.upload_fileobj(
        file,
        os.environ['S3_BUCKET_NAME'],
        filename,
        ExtraArgs={
            'Metadata': {
                'job_position': job_position,
                'uploaded_by': session['username']
            }
        }
    )
    
    flash('CV uploaded successfully! Processing will start shortly.', 'success')
    return redirect('/dashboard')
```

---

## 5. Sicurezza e Best Practices {#sicurezza}

### 5.1 Sicurezza Implementata

#### **1. Autenticazione e Autorizzazione**
- âœ… AWS Cognito per gestione utenti
- âœ… JWT tokens con scadenza (1 ora)
- âœ… Solo admin puÃ² creare utenti
- âœ… Password policy forte (8+ caratteri, uppercase, numbers)

#### **2. Network Security**
- âœ… S3 bucket **completamente privato** (no public access)
- âœ… SQS queue accessibile solo da S3 e Lambda
- âœ… Lambda con IAM roles a privilegi minimi

#### **3. Encryption**
- âœ… **At-rest**: S3 e DynamoDB cifrati con AES-256
- âœ… **In-transit**: HTTPS/TLS per tutte le comunicazioni
- âœ… Secrets gestiti tramite environment variables

#### **4. IAM Policies (Least Privilege)**

**Lambda Execution Role**:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject"  // SOLO lettura su S3
      ],
      "Resource": "arn:aws:s3:::smart-ats-cvs-dev-*/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:PutItem",
        "dynamodb:GetItem"
      ],
      "Resource": "arn:aws:dynamodb:us-east-1:*:table/smart-ats-candidates-*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "sqs:ReceiveMessage",
        "sqs:DeleteMessage",
        "sqs:GetQueueAttributes"
      ],
      "Resource": "arn:aws:sqs:us-east-1:*:smart-ats-cv-queue-*"
    }
  ]
}
```

### 5.2 Best Practices Cloud-Native

#### **1. Idempotency**
Lambda puÃ² ricevere stesso messaggio piÃ¹ volte â†’ uso `candidate_id` univoco per evitare duplicati

#### **2. Error Handling**
```python
try:
    # Process CV
    result = process_cv(cv_content)
except Exception as e:
    logger.error(f"Error processing CV: {str(e)}")
    # Non sollevare exception â†’ messaggio va in DLQ dopo 3 tentativi
    continue
```

#### **3. Monitoring**
- CloudWatch Logs per tutti i componenti
- CloudWatch Metrics per Lambda (invocations, errors, duration)
- Allarmi su errori critici

#### **4. Cost Optimization**
- S3 Lifecycle policies per eliminare versioni vecchie
- DynamoDB on-demand pricing (no overprovisioning)
- Lambda right-sized memory (512MB)

---

## 6. Testing e Deployment {#testing}

### 6.1 Testing Strategy

#### **Unit Tests** (Locale)
```python
# test_ranking_engine.py
def test_calculate_score():
    engine = RankingEngine()
    cv_data = {
        'skills': ['Python', 'AWS', 'Docker'],
        'experience_years': 5,
        'education': "Master's Degree"
    }
    
    score, skills_matched = engine.calculate_score(cv_data, 'Software Engineer')
    
    assert score > 50  # Candidato qualificato
    assert '3/5' in skills_matched  # 3 skills su 5
```

#### **Integration Tests** (AWS)
```bash
# Upload test CV
aws s3 cp test_cv.pdf s3://smart-ats-cvs-dev-*/cvs/

# Attendere processing (15 secondi)
sleep 15

# Verificare DynamoDB
aws dynamodb scan --table-name smart-ats-candidates-dev

# Verificare logs Lambda
aws logs tail /aws/lambda/smart-ats-cv-processor-dev --follow
```

### 6.2 CI/CD Pipeline (Progettato)

```yaml
# .github/workflows/deploy.yml
name: Deploy Smart ATS

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: SAM Build
        run: sam build --use-container
      
      - name: SAM Deploy
        run: |
          sam deploy \
            --stack-name smart-ats-stack-${{ github.ref_name }} \
            --capabilities CAPABILITY_IAM \
            --no-fail-on-empty-changeset
```

### 6.3 Deployment Workflow

```bash
# 1. Build SAM application (compila Lambda in Docker)
cd infrastructure
sam build --use-container

# 2. Validate template
sam validate --lint

# 3. Deploy to AWS
sam deploy \
  --stack-name smart-ats-stack-dev \
  --region us-east-1 \
  --parameter-overrides Environment=dev \
  --capabilities CAPABILITY_IAM

# 4. Get stack outputs
aws cloudformation describe-stacks \
  --stack-name smart-ats-stack-dev \
  --query 'Stacks[0].Outputs'

# 5. Configure Cognito user password
aws cognito-idp admin-set-user-password \
  --user-pool-id <USER_POOL_ID> \
  --username admin@smartats.com \
  --password SmartATS2026! \
  --permanent
```

---

## 7. Dimostrazione Pratica {#dimostrazione}

### 7.1 Demo Flow

**Step 1: Login**
```
1. Aprire browser: http://localhost:8080
2. Click "Recruiter Login"
3. Inserire credenziali:
   - Username: admin@smartats.com
   - Password: SmartATS2026!
4. Accesso alla Dashboard âœ…
```

**Step 2: Upload CV**
```
1. Dashboard â†’ "Upload New CV"
2. Selezionare Job Position: "Software Engineer"
3. Scegliere file PDF/DOCX
4. Click "Upload CV"
5. Messaggio: "CV uploaded successfully!" âœ…
```

**Step 3: Verifica Processing**
```
# Terminal 1: Monitor Lambda logs
aws logs tail /aws/lambda/smart-ats-cv-processor-dev --follow

# Output atteso:
# Processing CV from S3: s3://smart-ats-cvs-dev-.../john_doe.pdf
# Successfully processed candidate: John Doe with score: 75.5
```

**Step 4: View Results**
```
1. Dashboard â†’ Sezione "Candidate Rankings"
2. Tabella mostra candidato:
   - Nome: John Doe
   - Position: Software Engineer
   - Score: 75.5%
   - Skills Match: 4/5
   - Status: Processed âœ…
```

### 7.2 Verifica Risorse AWS

**S3 Bucket**:
```bash
aws s3 ls s3://smart-ats-cvs-dev-055316374175/cvs/
# Output: 2026-01-20 john_doe_20260120_170000.pdf
```

**DynamoDB**:
```bash
aws dynamodb scan --table-name smart-ats-candidates-dev
# Output: {Items: [{candidate_name: "John Doe", ranking_score: 75.5, ...}]}
```

**CloudWatch Metrics**:
```bash
# Lambda invocations ultime 24h
aws cloudwatch get-metric-statistics \
  --namespace AWS/Lambda \
  --metric-name Invocations \
  --dimensions Name=FunctionName,Value=smart-ats-cv-processor-dev \
  --start-time $(date -u -d '24 hours ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 3600 \
  --statistics Sum
```

---

## ğŸ“Š Metriche e Performance

### Costi Mensili Stimati (100 CV/mese)

| Servizio | Utilizzo | Costo/Mese |
|----------|----------|------------|
| Lambda | 100 invocazioni Ã— 2s | $0.00 (Free Tier) |
| S3 | 1 GB storage | $0.02 |
| DynamoDB | 100 write, 1000 read | $0.00 (Free Tier) |
| SQS | 100 messaggi | $0.00 (Free Tier) |
| Cognito | 10 utenti | $0.00 (Free Tier) |
| **TOTALE** | - | **~$0.02/mese** |

### Performance Metrics

- **Upload â†’ Visualizzazione**: ~15 secondi
- **Lambda Cold Start**: ~1.5s
- **Lambda Warm Execution**: ~800ms
- **DynamoDB Query Latency**: <10ms
- **Concurrent Processing**: Fino a 1000 CV simultanei

---

## ğŸ¯ Conclusioni

### Obiettivi Raggiunti

âœ… **Architettura serverless completa** su AWS  
âœ… **Processing asincrono** scalabile e resiliente  
âœ… **Sicurezza** con Cognito, IAM, encryption  
âœ… **Infrastructure as Code** con AWS SAM  
âœ… **Best practices** cloud-native implementate  
âœ… **Monitoring** completo con CloudWatch  

### Competenze Dimostrate

1. **Cloud Architecture Design**: Event-driven, serverless
2. **AWS Services**: 7 servizi integrati (S3, SQS, Lambda, DynamoDB, Cognito, API Gateway, SAM)
3. **Python Development**: Parser CV, scoring algorithm
4. **DevOps**: IaC, CI/CD planning, deployment automation
5. **Security**: IAM policies, encryption, authentication

### Possibili Estensioni Future

- **ML Integration**: AWS Textract per OCR avanzato
- **Email Notifications**: SES per notificare recruiter
- **Real-time Dashboard**: WebSockets per aggiornamenti live
- **Multi-tenancy**: Supporto multiple aziende
- **Advanced Analytics**: QuickSight dashboards

---

## ğŸ“š Repository e Documentazione

- **GitHub**: https://github.com/salvlea/Sistemi_Cloud
- **Documentazione completa**: `/docs/architecture.md`
- **API Specs**: `/docs/api_specs.md`
- **Quick Start Guide**: `/QUICKSTART.md`

---

**Fine Presentazione**

*Domande?* ğŸ™‹â€â™‚ï¸
